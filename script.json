{
  "title": "2026-01-22 今日のEEG論文まとめ",
  "dialogue": [
    {
      "speaker": "ずんだもん",
      "text": "2026年1月22日、今日のEEG論文まとめです。"
    },
    {
      "speaker": "四国めたん",
      "text": "今日もごきげんよう。さっそく、最新のEEG研究を紐解いていきましょう。"
    },
    {
      "speaker": "ずんだもん",
      "text": "まずは第1論文、モバイルEEGで視聴覚環境の注意追跡をやってるんだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、従来の注意追跡研究が実験室限定で音声のみだった点だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、日常的な二人話し相手の状況で注意を追跡できるか試すことだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は44電極の頭皮EEGと20cEEGridを用い、持ち運び可能なセットでデータ収集。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、P2ピークで注視と無視の差が有意だったんだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "しかも、注意切り替えと自然会話でも同様の差が観測された。"
    },
    {
      "speaker": "ずんだもん",
      "text": "限界は、切り替え時の性能差が小さかった点だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "今後は、より複雑な会話シナリオでの検証が必要だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "次は第2論文、Auditory Brain Passage Retrievalだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、クエリ形成が情報検索で難しい点にある。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、視覚刺激だけでなく聴覚EEGを使って検索性能を上げることだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は、双方向エンコーダと4種類のプーリングを組み合わせたモデル。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、聴覚EEGが視覚より優れていて、CLSプーリングでクロスセンサ訓練が31%改善したんだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "限界は、データセットが限定的である点。"
    },
    {
      "speaker": "四国めたん",
      "text": "今後は、より大規模な聴覚データで検証が必要だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "第3論文、RL-BioAugでデータ拡張を学習させるんだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、EEGの非定常性がランダム拡張を不適切にする点だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、ラベル効率的なRLエージェントで最適拡張を見つけることだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は、10%のラベルでエージェントを訓練し、タスクごとに最適戦略を選択。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、睡眠ステージで62%の時間マスク、発作検出では77%がCrop&Resizeだった。"
    },
    {
      "speaker": "四国めたん",
      "text": "性能は、ランダムより9.69%と8.80%改善した。"
    },
    {
      "speaker": "四国めたん",
      "text": "限界は、RLエージェントの計算コストが高い点だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "将来は、より軽量なポリシー学習が課題だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "第4論文、Audio Outperforms Text for Visual Decoding。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、視覚情報のデコーディングがテキスト表現に依存していた点だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、音声表現を用いてゼロショットデコーディングの精度向上だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は、音声と視覚をマルチモーダルに結合したアラインメントモデル。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、音声がテキストより高精度で計算効率も良かった。"
    },
    {
      "speaker": "四国めたん",
      "text": "限界は、音声データの取得コストが高い点だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "今後は、音声収集の自動化が必要だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "第5論文、EEG-Titansで長期発作予測をやってるんだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、発作予測が長時間の前兆を捉えることが難しい点だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、長期文脈を保持しつつ短期異常も検知するモデル作成だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は、スライディングウィンドウ注意とリカレントメモリを組み合わせたデュアルブランチ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、18人で平均99.46%の感度を達成。"
    },
    {
      "speaker": "四国めたん",
      "text": "限界は、ノイズ多いデータで誤検知が増える点だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "対策として、階層的文脈戦略でFPRを0.00に近づけた。"
    },
    {
      "speaker": "ずんだもん",
      "text": "第6論文、ConvMambaNetでリアルタイム発作検出を実現。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、従来のCNNが長期依存を捉えにくい点だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、CNNとMambaSSMを融合して時系列特徴を強化することだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は、Mamba-SSMブロックをCNNに埋め込み、空間・長期時間特性を同時取得。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、CHB-MITで99%の精度を達成。"
    },
    {
      "speaker": "四国めたん",
      "text": "限界は、クラス不均衡への対処が難しい点だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "しかし、実装はリアルタイムで可能だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "第7論文、LLMで音楽療法のEEG解析を自動化。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、専門家解釈が必要なEEG解析のハードルだ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、LLMで解析報告と音楽提案を自動生成することだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は、信号処理モジュールとLLM推論エージェントを統合。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、非専門家でも理解しやすい報告が得られた。"
    },
    {
      "speaker": "四国めたん",
      "text": "限界は、LLMの解釈精度とデータ量が課題だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "今後は、より多様な音楽データで検証が必要だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "第8論文、HCFTでEEGデコーディングを軽量化。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、従来のTransformerが計算量過多だった点だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、双方向CNNと階層Transformerで多尺度表現を学習することだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は、時間・時空間畳み込みブランチとCross-Attentionで統合。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、BCI CompetitionとCHB-MITで高精度を示した。"
    },
    {
      "speaker": "四国めたん",
      "text": "限界は、Dynamic Tanh正規化の安定性が完全ではない点だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "将来は、さらに軽量化と汎用性向上が課題だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "第9論文、簡単モデルで視覚情報を脳から復元。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、脳活動から画像を生成する難しさだ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、時系列注意と浅いMLPで高精度を達成することだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は、THINGS Ventral Stream Spiking Datasetを用い、Temporal Attention+MLPで70%のTop-1取得。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、単純モデルが複雑なモデルを上回った。"
    },
    {
      "speaker": "四国めたん",
      "text": "限界は、データスケールでの減衰が観測された点だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "今後は、生成パイプラインの改良が必要だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "第10論文、うつ病検出にCNN-GRUとMRMRを組み合わせた。"
    },
    {
      "speaker": "四国めたん",
      "text": "背景は、主観的診断の限界だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "目的は、EEGから客観的うつ病判定を行うことだ。"
    },
    {
      "speaker": "四国めたん",
      "text": "手法は、CNNで空間特徴を抽出しGRUで時間情報を統合。"
    },
    {
      "speaker": "ずんだもん",
      "text": "結果は、MRMRで特徴選択後に高い分類精度を示した。"
    },
    {
      "speaker": "四国めたん",
      "text": "限界は、データ量と多様性が不足している点だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "将来は、より大規模な多施設データで検証が必要だ。"
    },
    {
      "speaker": "ずんだもん",
      "text": "最後に、未公開論文があるけど要約はないから不明だ。"
    },
    {
      "speaker": "四国めたん",
      "text": "それでは、今日のEEG論文まとめは以上です。"
    },
    {
      "speaker": "ずんだもん",
      "text": "次回もぜひお楽しみに。"
    },
    {
      "speaker": "四国めたん",
      "text": "ご清聴ありがとうございました。"
    }
  ],
  "references": [
    {
      "title": "Neural Tracking of Sustained Attention, Attention Switching, and Natural Conversation in Audiovisual Environments using Mobile EEG",
      "authors": "Johanna Wilroth, Oskar Keding, Martin A. Skoglund, Maria Sandsten, Martin Enqvist, Emina Alickovic",
      "url": "https://arxiv.org/abs/2601.15097v1",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-21T15:37:33Z"
    },
    {
      "title": "Auditory Brain Passage Retrieval: Cross-Sensory EEG Training for Neural Information Retrieval",
      "authors": "Niall McGuire, Yashar Moshfeghi",
      "url": "https://arxiv.org/abs/2601.14001v1",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-20T14:22:41Z"
    },
    {
      "title": "RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning",
      "authors": "Cheol-Hui Lee, Hwa-Yeon Lee, Dong-Joo Kim",
      "url": "https://arxiv.org/abs/2601.13964v2",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-20T13:38:01Z"
    },
    {
      "title": "Audio Outperforms Text for Visual Decoding",
      "authors": "Zhengdi Zhang, Hao Zhang, Wenjun Xia",
      "url": "https://arxiv.org/abs/2601.13866v1",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-20T11:30:41Z"
    },
    {
      "title": "EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory",
      "authors": "Tien-Dat Pham, Xuan-The Tran",
      "url": "https://arxiv.org/abs/2601.13748v1",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-20T09:03:49Z"
    },
    {
      "title": "ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection",
      "authors": "Md. Nishan Khan, Kazi Shahriar Sanjid, Md. Tanzim Hossain, Asib Mostakim Fony, Istiak Ahmed, M. Monir Uddin",
      "url": "https://arxiv.org/abs/2601.13234v1",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-19T17:08:34Z"
    },
    {
      "title": "Democratizing Music Therapy: LLM-Based Automated EEG Analysis and Progress Tracking for Low-Cost Home Devices",
      "authors": "Huixin Xue, Guangjun Xu, Shihong Ren, Xian Gao, Ruian Tie, Zhen Zhou, Hao Liu, Yue Gao",
      "url": "https://arxiv.org/abs/2601.12280v1",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-18T06:40:56Z"
    },
    {
      "title": "HCFT: Hierarchical Convolutional Fusion Transformer for EEG Decoding",
      "authors": "Haodong Zhang, Jiapeng Zhu, Yitong Chen, Hongqi Li",
      "url": "https://arxiv.org/abs/2601.12279v1",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-18T06:36:30Z"
    },
    {
      "title": "Simple Models, Rich Representations: Visual Decoding from Primate Intracortical Neural Signals",
      "authors": "Matteo Ciferri, Matteo Ferrante, Nicola Toschi",
      "url": "https://arxiv.org/abs/2601.11108v1",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-16T09:10:31Z"
    },
    {
      "title": "Depression Detection Based on Electroencephalography Using a Hybrid Deep Neural Network CNN-GRU and MRMR Feature Selection",
      "authors": "Mohammad Reza Yousefi, Hajar Ismail Al-Tamimi, Amin Dehghani",
      "url": "https://arxiv.org/abs/2601.10959v1",
      "doi": "",
      "source": "arXiv",
      "published": "2026-01-16T02:58:17Z"
    },
    {
      "title": "No Title",
      "authors": "Unknown",
      "url": "",
      "doi": "",
      "source": "Scopus",
      "published": ""
    }
  ],
  "date": "2026-01-22"
}